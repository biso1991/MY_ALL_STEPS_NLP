{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "5.9.2 Text Generation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0DQUKmp3dzL"
      },
      "source": [
        "تحميل المكتبات المطلوبة"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cVk7eZVQEmhS",
        "outputId": "13b13d83-0117-452f-b81e-790dddef8872",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import numpy\n",
        "import sys\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, LSTM\n",
        "from keras.utils import np_utils\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E9AHzWez3exu"
      },
      "source": [
        "قراءة الملفات"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ow-bKwJ1Emhg"
      },
      "source": [
        "with open(\"/content/Franknestein.txt\", encoding=\"utf8\") as text_file:\n",
        "    file = text_file.read()\n",
        "# print(file)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "94rYLdaf3fju"
      },
      "source": [
        "عدد دالة لتناول الكلمات و حذف كلمات التوقف"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pz_A6PM2Emhw"
      },
      "source": [
        "def tokenize_words(input):\n",
        "    # lowercase everything to standardize it\n",
        "    input = input.lower()\n",
        "\n",
        "    # instantiate the tokenizer\n",
        "    tokenizer = RegexpTokenizer(r'\\w+')\n",
        "    tokens = tokenizer.tokenize(input)\n",
        "\n",
        "    # if the created token isn't in the stop words, make it part of \"filtered\"\n",
        "    filtered = filter(lambda token: token not in stopwords.words('english'), tokens)\n",
        "    return \" \".join(filtered)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i793AvCuEmh7"
      },
      "source": [
        "processed_inputs = tokenize_words(file)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AO7B4tUf3g19"
      },
      "source": [
        "عدد الحروف"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trbL2DZHEmiI",
        "outputId": "76c701b6-dae8-4462-ff46-6ea50e15209b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "len(processed_inputs)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "269995"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2aCJJDgn3hTo"
      },
      "source": [
        "اول الف حرف"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xIjnt-QbEmiV",
        "outputId": "98c91c99-8e90-48ab-8c72-b5228141e00b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        }
      },
      "source": [
        "processed_inputs[:1000]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'project gutenberg frankenstein mary wollstonecraft godwin shelley ebook use anyone anywhere cost almost restrictions whatsoever may copy give away use terms project gutenberg license included ebook online www gutenberg net title frankenstein modern prometheus author mary wollstonecraft godwin shelley release date june 17 2008 ebook 84 last updated january 13 2018 language english character set encoding utf 8 start project gutenberg ebook frankenstein produced judith boss christy phillips lynn hanninen david meltzer html version al haines corrections menno de leeuw frankenstein modern prometheus mary wollstonecraft godwin shelley contents letter 1 letter 2 letter 3 letter 4 chapter 1 chapter 2 chapter 3 chapter 4 chapter 5 chapter 6 chapter 7 chapter 8 chapter 9 chapter 10 chapter 11 chapter 12 chapter 13 chapter 14 chapter 15 chapter 16 chapter 17 chapter 18 chapter 19 chapter 20 chapter 21 chapter 22 chapter 23 chapter 24 letter 1 _to mrs saville england _ st petersburgh dec 11th 17 r'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s3o3GUAz3jAx"
      },
      "source": [
        "حذف التكرار و ترتيبها"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXoxzvziEmii"
      },
      "source": [
        "chars = sorted(list(set(processed_inputs)))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "enDEAX5tEmiy",
        "outputId": "ec8b6916-3cf4-4bcd-81d5-ce78a569391a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "len(chars)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "43"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tGhVyddH3kHe"
      },
      "source": [
        "اول 15 حرف"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oeeApT1rEmjA",
        "outputId": "af8adc4e-eac1-4995-b15f-6fcaf790d003",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "chars[:15]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[' ', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '_', 'a', 'b', 'c']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B9Yxr3uh3k2v"
      },
      "source": [
        "عمل قاموس للتحويل من حرف لرقم"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vaE9nMjKEmjO"
      },
      "source": [
        "char_to_num = dict((c, i) for i, c in enumerate(chars))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-aSOdJi2Emja",
        "outputId": "39e80179-6a2f-4596-ef9e-9c7b07ed5969",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "char_to_num"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{' ': 0,\n",
              " '0': 1,\n",
              " '1': 2,\n",
              " '2': 3,\n",
              " '3': 4,\n",
              " '4': 5,\n",
              " '5': 6,\n",
              " '6': 7,\n",
              " '7': 8,\n",
              " '8': 9,\n",
              " '9': 10,\n",
              " '_': 11,\n",
              " 'a': 12,\n",
              " 'b': 13,\n",
              " 'c': 14,\n",
              " 'd': 15,\n",
              " 'e': 16,\n",
              " 'f': 17,\n",
              " 'g': 18,\n",
              " 'h': 19,\n",
              " 'i': 20,\n",
              " 'j': 21,\n",
              " 'k': 22,\n",
              " 'l': 23,\n",
              " 'm': 24,\n",
              " 'n': 25,\n",
              " 'o': 26,\n",
              " 'p': 27,\n",
              " 'q': 28,\n",
              " 'r': 29,\n",
              " 's': 30,\n",
              " 't': 31,\n",
              " 'u': 32,\n",
              " 'v': 33,\n",
              " 'w': 34,\n",
              " 'x': 35,\n",
              " 'y': 36,\n",
              " 'z': 37,\n",
              " 'æ': 38,\n",
              " 'è': 39,\n",
              " 'é': 40,\n",
              " 'ê': 41,\n",
              " 'ô': 42}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_dSs64LG3mHL"
      },
      "source": [
        "عدد الحروف في النص و عددها دون تكرار"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6p8CUowhEmjl",
        "outputId": "810c4757-e8f7-4735-e585-1f649c065fe0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "input_len = len(processed_inputs)\n",
        "vocab_len = len(chars)\n",
        "print (\"Total number of characters:\", input_len)\n",
        "print (\"Total vocab:\", vocab_len)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total number of characters: 269995\n",
            "Total vocab: 43\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-GsPJ5mV3mkx"
      },
      "source": [
        "اعداد المعاملات"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e4JSD7c4Emjw"
      },
      "source": [
        "seq_length = 100\n",
        "x_data = []\n",
        "y_data = []"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lk41m5Oz3nPE"
      },
      "source": [
        "تقطيع النص"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1SEtbJhsEmj7"
      },
      "source": [
        "# loop through inputs, start at the beginning and go until we hit\n",
        "# the final character we can create a sequence out of\n",
        "for i in range(0, input_len - seq_length, 1):\n",
        "    # Define input and output sequences\n",
        "    # Input is the current character plus desired sequence length\n",
        "    in_seq = processed_inputs[i:i + seq_length]\n",
        "\n",
        "    # Out sequence is the initial character plus total sequence length\n",
        "    out_seq = processed_inputs[i + seq_length]\n",
        "\n",
        "    # We now convert list of characters to integers based on\n",
        "    # previously and add the values to our lists\n",
        "    x_data.append([char_to_num[char] for char in in_seq])\n",
        "    y_data.append(char_to_num[out_seq])"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OtLva1Xk3nub"
      },
      "source": [
        "عدد الحروف"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0xdR9VOEmkF",
        "outputId": "4f856c4f-ad7a-47b5-fd64-3e515faf06a2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "n_patterns = len(x_data)\n",
        "print (\"Total Patterns:\", n_patterns)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Patterns: 269895\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kGiNpT353olV"
      },
      "source": [
        "غيير الابعاد"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9Bs2U0pEmkQ"
      },
      "source": [
        "X = numpy.reshape(x_data, (n_patterns, seq_length, 1))\n",
        "X = X/float(vocab_len)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x1vqEkhE3pI9"
      },
      "source": [
        "عمل \n",
        "\n",
        "One hot encoder\n",
        "\n",
        " للشبكة"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mG3oFiQrEmkc"
      },
      "source": [
        "y = np_utils.to_categorical(y_data)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZDAp1PO3p91"
      },
      "source": [
        "الشبكة"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29e0S1aoEmkt"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(256, return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(128))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(y.shape[1], activation='softmax'))"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "auTBRVWpEmlD"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cw4mkqxb3qt2"
      },
      "source": [
        "تحديد ملف لحفظ الاوزان"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_XTQrHvUEmla"
      },
      "source": [
        "filepath = \"model_weights_saved.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
        "desired_callbacks = [checkpoint]"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0AhNeTuf3sFJ"
      },
      "source": [
        "التدريب"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7gg6YBhCEmlm",
        "outputId": "20e7dfb6-a3a5-4faf-8103-e2a94fddd450",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.fit(X, y, epochs=20, batch_size=256, callbacks=desired_callbacks)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "1054/1055 [============================>.] - ETA: 0s - loss: 2.9015\n",
            "Epoch 00001: loss improved from inf to 2.90142, saving model to model_weights_saved.hdf5\n",
            "1055/1055 [==============================] - 58s 55ms/step - loss: 2.9014\n",
            "Epoch 2/20\n",
            "1054/1055 [============================>.] - ETA: 0s - loss: 2.6353\n",
            "Epoch 00002: loss improved from 2.90142 to 2.63526, saving model to model_weights_saved.hdf5\n",
            "1055/1055 [==============================] - 57s 54ms/step - loss: 2.6353\n",
            "Epoch 3/20\n",
            "1054/1055 [============================>.] - ETA: 0s - loss: 2.4818\n",
            "Epoch 00003: loss improved from 2.63526 to 2.48181, saving model to model_weights_saved.hdf5\n",
            "1055/1055 [==============================] - 57s 54ms/step - loss: 2.4818\n",
            "Epoch 4/20\n",
            "1054/1055 [============================>.] - ETA: 0s - loss: 2.3549\n",
            "Epoch 00004: loss improved from 2.48181 to 2.35490, saving model to model_weights_saved.hdf5\n",
            "1055/1055 [==============================] - 57s 54ms/step - loss: 2.3549\n",
            "Epoch 5/20\n",
            "1054/1055 [============================>.] - ETA: 0s - loss: 2.2548\n",
            "Epoch 00005: loss improved from 2.35490 to 2.25474, saving model to model_weights_saved.hdf5\n",
            "1055/1055 [==============================] - 57s 54ms/step - loss: 2.2547\n",
            "Epoch 6/20\n",
            "1054/1055 [============================>.] - ETA: 0s - loss: 2.1772\n",
            "Epoch 00006: loss improved from 2.25474 to 2.17710, saving model to model_weights_saved.hdf5\n",
            "1055/1055 [==============================] - 57s 54ms/step - loss: 2.1771\n",
            "Epoch 7/20\n",
            "1054/1055 [============================>.] - ETA: 0s - loss: 2.1111\n",
            "Epoch 00007: loss improved from 2.17710 to 2.11113, saving model to model_weights_saved.hdf5\n",
            "1055/1055 [==============================] - 58s 55ms/step - loss: 2.1111\n",
            "Epoch 8/20\n",
            "1054/1055 [============================>.] - ETA: 0s - loss: 2.0568\n",
            "Epoch 00008: loss improved from 2.11113 to 2.05683, saving model to model_weights_saved.hdf5\n",
            "1055/1055 [==============================] - 58s 55ms/step - loss: 2.0568\n",
            "Epoch 9/20\n",
            "1054/1055 [============================>.] - ETA: 0s - loss: 2.0135\n",
            "Epoch 00009: loss improved from 2.05683 to 2.01346, saving model to model_weights_saved.hdf5\n",
            "1055/1055 [==============================] - 58s 55ms/step - loss: 2.0135\n",
            "Epoch 10/20\n",
            "1054/1055 [============================>.] - ETA: 0s - loss: 1.9769\n",
            "Epoch 00010: loss improved from 2.01346 to 1.97693, saving model to model_weights_saved.hdf5\n",
            "1055/1055 [==============================] - 57s 54ms/step - loss: 1.9769\n",
            "Epoch 11/20\n",
            "1054/1055 [============================>.] - ETA: 0s - loss: 1.9426\n",
            "Epoch 00011: loss improved from 1.97693 to 1.94262, saving model to model_weights_saved.hdf5\n",
            "1055/1055 [==============================] - 57s 54ms/step - loss: 1.9426\n",
            "Epoch 12/20\n",
            "1054/1055 [============================>.] - ETA: 0s - loss: 1.9109\n",
            "Epoch 00012: loss improved from 1.94262 to 1.91105, saving model to model_weights_saved.hdf5\n",
            "1055/1055 [==============================] - 58s 55ms/step - loss: 1.9111\n",
            "Epoch 13/20\n",
            "1054/1055 [============================>.] - ETA: 0s - loss: 1.8859\n",
            "Epoch 00013: loss improved from 1.91105 to 1.88592, saving model to model_weights_saved.hdf5\n",
            "1055/1055 [==============================] - 58s 55ms/step - loss: 1.8859\n",
            "Epoch 14/20\n",
            "1054/1055 [============================>.] - ETA: 0s - loss: 1.8622\n",
            "Epoch 00014: loss improved from 1.88592 to 1.86230, saving model to model_weights_saved.hdf5\n",
            "1055/1055 [==============================] - 57s 54ms/step - loss: 1.8623\n",
            "Epoch 15/20\n",
            "1054/1055 [============================>.] - ETA: 0s - loss: 1.8364\n",
            "Epoch 00015: loss improved from 1.86230 to 1.83640, saving model to model_weights_saved.hdf5\n",
            "1055/1055 [==============================] - 58s 55ms/step - loss: 1.8364\n",
            "Epoch 16/20\n",
            "1054/1055 [============================>.] - ETA: 0s - loss: 1.8224\n",
            "Epoch 00016: loss improved from 1.83640 to 1.82233, saving model to model_weights_saved.hdf5\n",
            "1055/1055 [==============================] - 58s 55ms/step - loss: 1.8223\n",
            "Epoch 17/20\n",
            "1054/1055 [============================>.] - ETA: 0s - loss: 1.8044\n",
            "Epoch 00017: loss improved from 1.82233 to 1.80436, saving model to model_weights_saved.hdf5\n",
            "1055/1055 [==============================] - 57s 54ms/step - loss: 1.8044\n",
            "Epoch 18/20\n",
            "1054/1055 [============================>.] - ETA: 0s - loss: 1.7877\n",
            "Epoch 00018: loss improved from 1.80436 to 1.78772, saving model to model_weights_saved.hdf5\n",
            "1055/1055 [==============================] - 58s 55ms/step - loss: 1.7877\n",
            "Epoch 19/20\n",
            "1054/1055 [============================>.] - ETA: 0s - loss: 1.7719\n",
            "Epoch 00019: loss improved from 1.78772 to 1.77183, saving model to model_weights_saved.hdf5\n",
            "1055/1055 [==============================] - 58s 55ms/step - loss: 1.7718\n",
            "Epoch 20/20\n",
            "1054/1055 [============================>.] - ETA: 0s - loss: 1.7585\n",
            "Epoch 00020: loss improved from 1.77183 to 1.75855, saving model to model_weights_saved.hdf5\n",
            "1055/1055 [==============================] - 58s 55ms/step - loss: 1.7585\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7ff9326c86a0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ur5gLmAh3tSV"
      },
      "source": [
        "فتح الملف المحفوظ , وتحميل الاوزان"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cs8Y7Qd7Emlz"
      },
      "source": [
        "filename = \"model_weights_saved.hdf5\"\n",
        "model.load_weights(filename)\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eWqvAmry3uLt"
      },
      "source": [
        "عمل القاموس"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRS8roApEml9"
      },
      "source": [
        "num_to_char = dict((i, c) for i, c in enumerate(chars))"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oayGZXwO3up1"
      },
      "source": [
        "عمل رقم عشوائي لاختيار 100 حرف من النص لتبدا به الشبكة"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0ubaLYlEmmH",
        "outputId": "61d559b4-008e-407f-febc-f4a9a018ed95",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "start = numpy.random.randint(0, len(x_data) - 1)\n",
        "pattern = x_data[start]\n",
        "print(\"Random Seed:\")\n",
        "print(\"\\\"\", ''.join([num_to_char[value] for value in pattern]), \"\\\"\")"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Random Seed:\n",
            "\" old man desire left alone cottage children departed took guitar played several mournful sweet airs s \"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PPvPE34L3vbR"
      },
      "source": [
        "التوقع"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ohn8uq8EmmT",
        "outputId": "e38107f7-4d1c-4036-d8bf-59f789dd5a71",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for i in range(1000):\n",
        "    x = numpy.reshape(pattern, (1, len(pattern), 1))\n",
        "    x = x / float(vocab_len)\n",
        "    prediction = model.predict(x, verbose=0)\n",
        "    index = numpy.argmax(prediction)\n",
        "    result = num_to_char[index]\n",
        "    seq_in = [num_to_char[value] for value in pattern]\n",
        "\n",
        "    sys.stdout.write(result)\n",
        "\n",
        "    pattern.append(index)\n",
        "    pattern = pattern[1:len(pattern)]"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ea sears sea sears sea sears sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fTxtPXPfGCcs"
      },
      "source": [
        ""
      ],
      "execution_count": 25,
      "outputs": []
    }
  ]
}