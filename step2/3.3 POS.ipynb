{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1 = nlp('''Health education encourages voluntary behavioral changes and positive influences. \n",
    "It can happen at the individual, group, institutional, \n",
    "community, or systemic level. \n",
    "It attempts to address attitudes, behaviors, and skills that can improve wellness.\n",
    "\n",
    "''')\n",
    "\n",
    "\n",
    "for token in doc1:\n",
    "    print('Words is   : ' , token.text)\n",
    "    print('POS is   : ' , token.pos ,'===',token.pos_  , '===', spacy.explain(token.pos_))\n",
    "    print('Dep is   : ' , token.dep , '===',token.dep_, '===', spacy.explain(token.dep_))\n",
    "    print('Tag is   : ' , token.tag , '===',token.tag_, '===', spacy.explain(token.tag_))\n",
    "    print('-----------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for token in doc1:\n",
    "    print(f'{token.text:{10}} {token.pos_:{8}} {token.tag_:{6}} {spacy.explain(token.tag_)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(u'I read book now.')\n",
    "r = doc[1]\n",
    "print(f'{r.text:{10}} {r.pos_:{8}} {r.tag_:{6}} {spacy.explain(r.tag_)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(u'I read a book on NLP.')\n",
    "r = doc[1]\n",
    "print(f'{r.text:{10}} {r.pos_:{8}} {r.tag_:{6}} {spacy.explain(r.tag_)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "POS_counts = doc1.count_by(spacy.attrs.POS)\n",
    "for k,v in sorted(POS_counts.items()):\n",
    "    print(f'{k}. {doc1.vocab[k].text:{5}}: {v}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TAG_counts = doc1.count_by(spacy.attrs.TAG)\n",
    "\n",
    "for k,v in sorted(TAG_counts.items()):\n",
    "    print(f'{k}. {doc1.vocab[k].text:{4}}: {v}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "DEP_counts = doc1.count_by(spacy.attrs.DEP)\n",
    "\n",
    "for k,v in sorted(DEP_counts.items()):\n",
    "    print(f'{k}. {doc1.vocab[k].text:{4}}: {v}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import state_union\n",
    "from nltk.tokenize import PunktSentenceTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'Moses supposes his toeses are roses but moses supposes erroneously'\n",
    "\n",
    "for w , m in nltk.pos_tag(nltk.word_tokenize(text)):\n",
    "    print(f'word : ({w}), type : ({m}) , means :  ({spacy.explain(m)})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enttext = '''\n",
    "Thomas Gradgrind, sir.  A man of realities.  A man of facts and calculations.  A man who proceeds upon the principle that\n",
    "two and two are four, and nothing over, and who is not to be talked into allowing for anything over.  Thomas Gradgrind, \n",
    "sir—peremptorily Thomas—Thomas Gradgrind.  With a rule and a pair of scales, and the multiplication table always in his pocket, \n",
    "sir, ready to weigh and measure any parcel of human nature, and tell you exactly what it comes to.  It is a mere question of\n",
    "figures, a case of simple arithmetic.  You might hope to get some other nonsensical belief into the head of George Gradgrind, or Augustus Gradgrind, or John Gradgrind, or Joseph Gradgrind (all supposititious, non-existent persons), but into the head of Thomas Gradgrind—no, sir!\n",
    "\n",
    "In such terms Mr. Gradgrind always mentally introduced himself, whether to his private circle of acquaintance, or to the public in general.  In such terms, no doubt, substituting the words ‘boys and girls,’ for ‘sir,’ Thomas Gradgrind now presented Thomas Gradgrind to the little pitchers before him, who were to be filled so full of facts.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_sent_tokenizer = PunktSentenceTokenizer(text)\n",
    "tokenized = custom_sent_tokenizer.tokenize(text)\n",
    "tokenized[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tokenized[:5]:\n",
    "    for w , m in nltk.pos_tag(nltk.word_tokenize(i)):\n",
    "        print(f'word : ({w}), type : ({m}) , means :  ({spacy.explain(m)})')\n",
    "    print('-----------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re           \n",
    "train_text = state_union.raw(\"2005-GWBush.txt\")\n",
    "sample_text = state_union.raw(\"2006-GWBush.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_sent_tokenizer = PunktSentenceTokenizer(train_text)\n",
    "tokenized = custom_sent_tokenizer.tokenize(sample_text)\n",
    "tokenized[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tokenized[:5]:\n",
    "    for w , m in nltk.pos_tag(nltk.word_tokenize(i)):\n",
    "        print(f'word : ({w}), type : ({m}) , means :  ({spacy.explain(m)})')\n",
    "    print('-----------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1 = nlp('''ضمت مؤلفات الخوارزمي كتاب الجمع والتفريق\n",
    "في الحساب الهندي، وكتاب رسم الربع المعمور، وكتاب تقويم البلدان، وكتاب العمل بالأسطرلاب، \n",
    "وكتاب \"صورة الأرض \" الذي اعتمد فيه على كتاب المجسطي لبطليموس مع إضافات وشروح\n",
    "وتعليقات، وأعاد كتابة كتاب الفلك الهندي المعروف باسم \"السند هند الكبير\" الذي ترجم إلى اللغة\n",
    "العربية زمن الخليفة المنصور فأعاد الخوارزمي كتابته وأضاف إليه وسمي كتابه \"السند هند الصغير\".\n",
    "\n",
    "وقد عرض في كتاب المختصر في حساب الجبر والمقابلة أول حل منهجي\n",
    "للمعادلات الخطية والمعادلات التربيعية مستعملا في ذلك الطريقة المعروفة باسم إكمال المربع. ويعتبر مؤسس علم الجبر،\n",
    "(اللقب الذي يتقاسمه مع ديوفانتوس) في القرن الثاني عشر، ولقد قدمت ترجمات اللاتينية عن حسابه على الأرقام الهندية، \n",
    "النظام العشري إلى العالم الغربي. نقح الخوارزمي كتاب الجغرافيا لكلاوديوس بطليموس وكتب في علم الفلك والتنجيم.\n",
    "''')\n",
    "\n",
    "\n",
    "for token in doc1:\n",
    "    print('Words is   : ' , token.text)\n",
    "    print('POS is   : ' , token.pos ,'===',token.pos_  , '===', spacy.explain(token.pos_))\n",
    "    print('Dep is   : ' , token.dep , '===',token.dep_, '===', spacy.explain(token.dep_))\n",
    "    print('Tag is   : ' , token.tag , '===',token.tag_, '===', spacy.explain(token.tag_))\n",
    "    print('-----------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for token in doc1:\n",
    "    print(f'{token.text:{10}} {token.pos_:{8}} {token.tag_:{6}} {spacy.explain(token.tag_)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "POS_counts = doc1.count_by(spacy.attrs.POS)\n",
    "for k,v in sorted(POS_counts.items()):\n",
    "    print(f'{k}. {doc1.vocab[k].text:{5}}: {v}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TAG_counts = doc1.count_by(spacy.attrs.TAG)\n",
    "\n",
    "for k,v in sorted(TAG_counts.items()):\n",
    "    print(f'{k}. {doc1.vocab[k].text:{4}}: {v}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "DEP_counts = doc1.count_by(spacy.attrs.DEP)\n",
    "\n",
    "for k,v in sorted(DEP_counts.items()):\n",
    "    print(f'{k}. {doc1.vocab[k].text:{4}}: {v}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
